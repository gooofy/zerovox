
model:
  emb_dim           : 128  # phoneme embedding size     medium: 256, base: 128, small: 128, tiny: 128
  emb_reduction     : 1    #                            medium:   1, base:   1, small:   2, tiny:   4
  punct_emb_dim     : 16   # punctuation embedding size medium:  16, base:  16, small:  16, tiny:  16
  dpe_emb_dim       : 32   # embedding size for _d_uration, _p_itch and _e_nergy

  encoder:
    depth           : 2    #         medium: 2, base: 2, small: 2, tiny: 2
    n_heads         : 2    #         medium: 2, base: 2, small: 1, tiny: 1
    kernel_size     : 5    #         medium: 5, base: 5, small: 3, tiny: 3
    expansion       : 2    # MixFFN, medium: 2, base: 2, small: 1, tiny: 1

  decoder:
#    max_seq_len      : 3500 # 1000
    max_seq_len      : 1500 # 1000
    n_layers         : 6
    n_head           : 2
    conv_filter_size : 1024
    conv_kernel_size : [9, 1]
    dropout          : 0.2

  gst:
    n_style_tokens  : 2000 # medium: 2000, base: 2000, small: 2000, tiny: 500
    n_heads         : 8
    ref_enc_filters : [32, 32, 64, 64, 128, 128]

training:
    max_epochs      : 100
    warmup_epochs   : 10
    val_epochs      : 1

    weight_decay    : 0.00001
    lr              : 0.0001
    grad_clip       : 1.0

    batch_size      : 8
