
model:
  emb_dim           : 128  # phoneme embedding size
  emb_reduction     : 1    # 1 -> no phoneme embedding reduction
  punct_emb_dim     : 16   # punctuation embedding size

  encoder:
    depth           : 2
    n_heads         : 2
    kernel_size     : 5
    expansion       : 2    # MixFFN expansion

  decoder:
    block_depth     : 3
    n_blocks        : 3
    kernel_size     : 5

  gst:
    n_style_tokens  : 10
    n_heads         : 8
    ref_enc_filters : [32, 32, 64, 64, 128, 128]

training:
    max_epochs      : 1000
    warmup_epochs   : 25
    val_epochs      : 2

    weight_decay    : 0.00001
    lr              : 0.0001
    grad_clip       : 1.0

    batch_size      : 32
